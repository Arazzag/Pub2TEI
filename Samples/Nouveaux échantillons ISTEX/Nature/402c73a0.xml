<?xml version="1.0"?>
<?Pub EntList alpha amp beta bull cir cirf copy delta dtri dtrif gamma kappa  mdash mu ndash omega pi plusmn psi rArr rho sect squ squf squshf star starf  trade utri utrif?>
<!DOCTYPE article PUBLIC "-//NPG//DTD XML Article//EN" "NPG_XML_Article.dtd" [
<!ENTITY figf1 PUBLIC "-//NatureAmerica//FICI 35011569//EN" "//snapple/web_d/web/npg/nature/journal/v402/n6761supp/images/402c73aa.2.gif" NDATA ITEM>
<!ENTITY figf2 PUBLIC "-//NatureAmerica//FICI 35011570//EN" "//snapple/web_d/web/npg/nature/journal/v402/n6761supp/images/402c73ab.2.gif" NDATA ITEM>
]>
<article id="35011567" language="eng" publish="issue" relation="no" origsrc="yes">
    <!--402c73a0-->
    <suppfm supptype="editorial">
        <suppmast>
            <jtl>Nature</jtl>
            <suppttl>Impacts of foreseeable science</suppttl>
            <vol>402</vol>
            <iss>6761supp</iss>
            <?Pub Caret?>
            <idt>19991202</idt>
        </suppmast>
        <parent>
            <jtl>Nature</jtl>
            <vol>402</vol>
            <iss>6761</iss>
            <idt>19991202</idt>
            <issn type="print">0028-0836</issn>
            <cpg>
                <cpy>1999</cpy>
                <cpn>Macmillan Magazines Ltd.</cpn>
            </cpg>
        </parent>
        <categ id="categtxt"/>
        <categtxt>impacts</categtxt>
        <pp>
            <spn>C73</spn>
            <epn>C76</epn>
            <cnt>4</cnt>
        </pp>
    </suppfm>
    <fm>
        <atl>Transitions still to be made</atl>
        <aug>
            <cau>
                <fnm>Philip</fnm>
                <snm>Ball</snm>
                <inits>P</inits>
                <corf rid="c1"/>
            </cau>
            <caff><coid id="c1"/>Philip Ball is a consultant editor for <i>Nature</i>. <newline/>e-mail: <email> p.ball@nature.com</email></caff>
        </aug>
        <stndfrst>A collection of many particles all interacting according to simple, local rules can show behaviour that is anything but simple or predictable. Yet such systems constitute most of the
            tangible Universe, and the theories that describe them continue to represent one of the most useful contributions of physics.</stndfrst>
    </fm>
    <bdy>
        <p>Physics in the twentieth century will probably be remembered for quantum mechanics, relativity and the Standard Model of particle physics. Yet the conceptual framework within which most
            physicists operate is not necessarily defined by the first of these and makes reference only rarely to the second two. The advances that have taken place in cosmology, high-energy physics
            and quantum theory are distinguished in being important not only scientifically but also philosophically, and surely that is why they have impinged so forcefully on the consciousness of
            our culture.</p>
        <p>But the central scaffold of modern physics is a less familiar construction &mdash; one that does not bear directly on the grand questions that physicists are popularly expected to address
            but instead defines our current understanding of phenomena at the prosaic energy and length scales characteristic of our everyday experience. Statistical physics, and more specifically the
            theory of transitions between states of matter, more or less defines what we know about &lsquo;everyday&rsquo; matter and its transformations.</p>
        <p>Moreover, it provides the conceptual apparatus for tackling complex collective quantum phenomena of intense topical interest such as Bose&ndash;Einstein condensation (in which a collection
            of particles all occupy the same quantum ground state) and high-temperature superconductivity (that is, superconductivity above about 35 K). Many of the states of condensed matter that
            promise new technological applications, ranging from block copolymers to magnetic multilayers, can be understood as the consequence of the kind of collective behaviour that statistical
            physics describes.</p>
        <p>There are still central issues in cosmology and high-energy physics whose solution requires an understanding of phase transitions, not least the primordial symmetry-breaking transitions
            that distinguished the fundamental forces and gave particles their masses by means of the Higgs mechanism. And in its most generalized form, statistical physics is promising to offer
            insights into phenomena once considered outside the physicist's domain: traffic flow, economics, cell biology and allometric scaling (the relation of biological functions to body mass), to
            name a few.</p>
        <crosshd>Critical ideas</crosshd>
        <p>&lsquo;Phase transition&rsquo; is today a debased term &mdash; like the classical equivalent of &lsquo;quantum leap&rsquo;, it tends to attach itself to any abrupt change in a system's
            behaviour. Does a single molecule, such as a protein, undergo a phase transition if it abruptly changes conformation? In the strict sense, no. A genuine transition requires that there be
            some singularity in a thermodynamic potential (such as the Gibbs free energy), which in itself requires that one can characterize the states of the system in a &lsquo;thermodynamic
            limit&rsquo; of infinite system size. But too much generality may be no bad thing, if it drives home the message that phase transitions occur not only when a liquid freezes or evaporates
            but also throughout the (once sub-microscopic) Universe as it cools, or in a superfluid as its viscosity vanishes. The point is that phase transitions are global and abrupt &mdash; they
            show matter behaving at its most nonlinear, with effects quite out of proportion to cause.</p>
        <p>That such a versatile discipline as statistical physics should have remained so well hidden that only aficionados recognize its importance is a puzzle for science historians to ponder. (The
            topic has, for example, in one way or another furnished 16 Nobel prizes in physics and chemistry.) Perhaps it says something about the discipline's humble beginnings, stemming from the
            work of Rudolf Clausius, James Clerk Maxwell and Ludwig Boltzmann on the kinetic theory of gases. In attempting to derive the gas laws of Robert Boyle and Joseph Louis Gay-Lussac from an
            analysis of the energy and motion of individual particles, Clausius was putting thermodynamics on a microscopic basis. But from a modern perspective, his programme was deeper still: he was
            attempting to understand the collective behaviour of interacting, many-body systems. This, it might be argued, is the defining objective of statistical physics in all its guises.</p>
        <p>At least with (dilute) gases one can afford to neglect interparticle attractive forces with some justification. Phase transitions enter into the picture, however, when those forces are
            included. Johannes Diderik van der Waals, who introduced such forces in a heuristic manner using what we would now call a mean-field theory, found that he could describe the
            gas&ndash;liquid transition. In van der Waals' theory, the particles have a hard repulsive core and an infinitesimally small attraction of infinite range (although this is not the way the
            Dutchman expressed it).</p>
        <p>Van der Waals was awarded the Nobel prize in 1910 and is regarded as something of a founding father for statistical physics. So far did his vision penetrate that in 1998 the physicist Ben
            Widom, in his Boltzmann Medal address, could still ask &ldquo;what do we know that van der Waals did not know?&rdquo;, and answer &ldquo;not very much&rdquo;<bibr rid="b1"/>. In
            particular, he was well aware not only of the gas&ndash;liquid critical point (which his equation predicts) but also of the existence of critical exponents, which describe mathematically
            how various properties vanish or diverge at the critical point. It is at this unique point in the &lsquo;phase space&rsquo; of temperature, pressure and density that a liquid and gas cease
            to be distinct and separated by a phase transition: above the critical temperature, there is only one fluid phase. Thermally driven fluctuations in density of the liquid and gas (caused by
            the mere randomness of particle motions) become increasingly pronounced as the critical point is approached; and their range becomes infinite exactly at criticality, dragging with them
            so-called &lsquo;response functions&rsquo; such as the fluid's compressibility.</p>
        <p>From the 1960s to the 1980s, nothing obsessed statistical physicists more than critical points. It seems strange, at first glance, that so much attention should be focused on a specific
            location in the phase diagram; but the reasons are twofold. First, the behaviour of a system at its critical point also determines its behaviour in the broad vicinity too, within the
            so-called critical region. The fluctuations that overwhelm the system at the critical point remain significant well beyond it; one of the reasons why the (controversial) idea of a
            high-pressure, low-temperature liquid&ndash;liquid critical point in water<bibr rid="b2"/> is so stimulating is that it might be expected to affect the liquid's behaviour under everyday
            conditions.</p>
        <p>But second, behaviour of a system at a critical point is like a badge of identification: it reveals kinships between different systems. Liquid&ndash;gas criticality and the behaviour of
            some magnets at their Curie point (the temperature above which they lose their ferromagnetism) have numerically equal critical exponents, and both can be modelled by the so-called Ising
            model, a lattice of two-state spins. Commonality of critical exponents gives rise to the idea of universality &mdash; that is, there are generic models in statistical physics that describe
            a variety of apparently different many-body systems. This means that solving one statistical mechanical problem generally delivers solutions for several others at the same time; it also
            implies that, fundamentally, many-body behaviour is determined only by broad-brush features such as the range of interparticle forces, the dimensionality, and the nature of the
            &lsquo;order parameter&rsquo; whose abrupt change from zero to a non-zero value defines the transition.</p>
        <p>Actually obtaining numerical values for critical exponents from first-principles theory is, however, another matter. Mean-field models offer analytic solutions, but they are strictly
            approximations in anything less than four spatial dimensions. Lars Onsager's <i>tour de force</i> in 1944 was the exact solution of the two-dimensional Ising model, providing exact numbers
            for the critical exponents. But the three-dimensional Ising model continues to rebuff the advances of theoreticians, and may be analytically insoluble.</p>
        <p>On the other hand, Kenneth Wilson's renormalization group theory provided in the 1960s and early 1970s a methodology for computing critical exponents numerically<bibr rid="b3"/>. It also
            pointed to the scale-invariant behaviour of fluctuations at the critical point: the fact that they occur on all length scales (<figr rid="f1">Fig. 1</figr>). (Gaussian random noise, in
            contrast, generates fluctuations of a characteristic average amplitude.)</p>
        <p>The principle of renormalization is to capture the fundamental probability distribution of the different states of the system by &lsquo;coarse-graining&rsquo; &mdash; a kind of mathematical
            squinting that eliminates extraneous detail. In a lattice model such as the Ising model, where the particles occupy sites on a regular grid, this involves calculating the average state of
            blocks of sites of specified size. Thus, whereas in the Ising model each site is assigned a two-state variable (&lsquo;up&rsquo; or &lsquo;down&rsquo; spin, say, represented by the black
            and white squares in <figr rid="f1">Fig. 1</figr>), the renormalized system contains a broader spectrum of averaged &lsquo;block variables&rsquo;. The interaction strength between blocks
            is rescaled accordingly.</p>
        <p>Progressive rescaling at different block sizes smoothes out ever-larger fluctuations. At temperatures either side of the critical temperature, this makes the system &lsquo;look&rsquo; ever
            further from criticality &mdash; it begins to resolve itself into one equilibrium state or the other. Exactly at the critical point, however, rescaling creates a patchwork rather like that
            in <figr rid="f1">Fig. 1</figr> (but with grey squares too) no matter how large the blocks become. The probability distribution of block variables settles down to an invariant form, peaked
            on &lsquo;black&rsquo; and &lsquo;white&rsquo;. The way in which this &lsquo;configuration flow&rsquo; evolves with changing length scale allows one to determine the precise value of the
            critical exponents &mdash; which are generally different, in one, two and three dimensions, from their mean-field values.</p>
        <crosshd>Quantum transitions</crosshd>
        <p>One of the richest veins of statistical mechanics presently being mined is found at its intersection with quantum mechanics. In particular, the many-body behaviour of electrons in condensed
            matter is extra-ordinarily rich. Correlated behaviour of electrons, in which they display a degree of collective or coherent dynamics, produces for example superconductivity, the integer
            and fractional quantum Hall effect (quantization of the Hall resistance, a measure of the voltage generated transverse to a current in a flat conducting sheet by an applied magnetic
            field), heavy-fermion behaviour (where conduction electrons acquire a very large &lsquo;effective mass&rsquo;), spin density waves and colossal magnetoresistance (CMR: a strong variation
            in electrical resistance owing to an applied magnetic field). All of these collective phenomena have in recent years been shown to underlie unexpected and potentially useful properties of
            novel materials: CMR, for instance, could potentially furnish highly sensitive read-out heads for magnetic memories.</p>
        <p>Superconductivity and superfluidity were always very evidently phase transitions &mdash; abrupt changes from a resistive to a non-resistive state, from a viscous to a non-viscous fluid. It
            was not until 1938, however, that the connection to statistical physics was made, when Fritz London pointed out<bibr rid="b4"/> that superfluidity in liquid helium might be the result of a
            kind of quantum condensation transition, in which the particles of the system become bosonic (that is, having integer spin) and so capable of occupying a single quantum state. It became
            generally accepted that these phenomena were examples of Bose&ndash;Einstein condensation, although the exact connection remains murky. </p>
        <p>In superconductivity the fermionic (spin-1/2) electrons become bosons by forming Cooper pairs, a many-body effect that (in the conventional low-temperature superconductors) results from an
            effective attraction mediated by the electrons' interaction with lattice vibrations (phonons) in the crystal. The full details of that process were determined in the 1950s by John Bardeen,
            Leon Cooper and Bob Schrieffer<bibr rid="b5"/>. It is significant that this is one of the many phase transitions that can be described in an approximate way by the phenomenological theory
            developed by Lev Landau and Vitaly Ginzburg in the 1950s. This stemmed from a very general mean-field model of phase transitions proposed earlier by Landau, whose contribution to this area
            of condensed-matter physics was pivotal. Landau's theory &mdash; a kind of generalized and augmented all-purpose van der Waals equation &mdash; remains the first port of call for any
            simplified model of a phase transition.</p>
        <p>The observation of Bose&ndash;Einstein condensation in atomic matter, seen for the first time in cooled sodium atoms in 1995<bibr rid="b6"/>, was itself another instance of a quantum phase
            transition &mdash; made possible now by laser cooling techniques.</p>
        <p>But is there any systematic way to accommodate quantum effects into the existing framework of statistical mechanics? The intense interest in correlated electron systems has now provided
            something of the kind. Conventionally, phase transitions are induced by changes in temperature &mdash; ice melts when heated, hot iron orders magnetically when cooled. All this is driven
            by changes in thermal fluctuations. &lsquo;Pure&rsquo; quantum phase transitions, meanwhile, take place at zero temperature, and are induced by altering some other parameter, such as the
            strength of an applied magnetic field, that affects quantum fluctuations. Classical fluctuations are frozen out at zero kelvin, but quantum fluctuations, which are a consequence of the
            uncertainty principle, remain. Their effect can be enhanced by altering some variable that alters the particles' (generally the electrons') state of localization, which is the equivalent
            in this case of altering the temperature.</p>
        <p>Quantum phase transitions provide a wider screen on which to scrutinize the still-enigmatic high-temperature superconductivity of layered copper oxide compounds. Superconductivity is now
            recognized as just one of the manifestations of the rich physics of the correlated electrons in these systems. There are magnetic interactions between the copper ions, which bear spins by
            virtue of their unpaired electrons. The prototype, lanthanum strontium copper oxide (close to the material studied by Georg Bednorz and Alex M&uuml;ller in 1986<bibr rid="b7"/>), is now
            recognized as an example of a diluted quantum antiferromagnet: diluted, that is, by the &lsquo;dopant&rsquo; strontium, which contributes positively charged mobile charge carriers (holes)
            to the copper-oxide layers. These holes may segregate into stripes, and the intervening phase, an insulating antiferromagnet, undergoes a magnetic quantum phase transition at some critical
            doping level.</p>
        <p>The behaviour of such systems at energy scales corresponding to temperatures above 100 K or so is now well understood; but the transition to a superconducting state at lower temperatures
            involves additional interactions of the electronic and spin degrees of freedom that have yet to be elucidated. At least one Nobel prize lies in wait for this enterprise.</p>
        <crosshd>Beyond equilibrium</crosshd>
        <p>Some of the major unresolved questions about the behaviour of both everyday and exotic matter are not so much a matter of being as of becoming. How does change in these many-particle
            ensembles occur? Traditionally, thermodynamics has concerned itself with equilibrium states. The particles might be in frantic motion, but the macroscopic properties are constant
            observables of the states that minimize free energy: pressure, density, temperature, magnetization and so forth. But how do systems actually get from state to state (particularly in cases
            of violent change, such as explosions or fracture)? And what about systems that do not reach equilibrium at all?</p>
        <p>First, there is the issue of irreversibility, which is to say, of the Second Law of Thermodynamics. Thermodynamic change has a directionality to it: entropy increases. The question is why.
            The answer most would give is Boltzmann's, which is purely probabilistic: entropy being related to the number of configurations available to the ensemble, those states will be achieved
            that have overwhelmingly greater probability. In the words of US physicist Josiah Willard Gibbs, &ldquo;the impossibility of an uncompensated decrease in entropy seems to be reduced to an
            improbability&rdquo;.</p>
        <p>But questions, even lingering doubts, persist. At the microscopic scale, the interaction between two particles is generally considered to be time-reversible: an encounter can be run in
            reverse without becoming a physical nonsense. So in what manner does the Second Law break down in going from irreversible macroscopic systems to reversible microscopic ones? And what is
            the relationship to the chaotic dynamics evident even in few-particle (sometimes even two-particle) systems? Perhaps instead there is some feature of the time-dependent evolution of
            probability distributions that forces irreversibility irrespective of scale? In other words, might irreversibility be built in at the microscopic level (contrary to the normally accepted
            tenet of microscopic reversibility)? Furthermore, the Boltzmann position requires that, as Richard Feynman put it, &ldquo;For some reason, the universe at one time had a very low
            entropy&rdquo;. But for what reason?</p>
        <p>Second, there is the question of whether a thermodynamic (and corresponding microscopic) description of non-equilibrium systems can be developed that mirrors the mature description of
            equilibrium states. As most processes of interest, from atmospheric circulation to cell metabolism, take place out of equilibrium, the issue is a pressing one.</p>
        <p>A key question is whether variational or minimization principles exist for selecting the most stable dynamic state, as is the case at equilibrium. Several have been suggested, amongst them
            Ilya Prigogine's minimal rate of entropy production for systems close to equilibrium; but there is no consensus, and at least some indication (the late Rolf Landauer's &lsquo;blowtorch
                theorem&rsquo;<bibr rid="b8"/>) that there can in fact be no universal principle of this sort, independent of a system's past history, away from equilibrium. In short, it matters not
            only what state a system is in, but how it got there.</p>
        <p>In fact, for all that one can postulate that entropy production must be positive in non-equilibrium processes (so that the Second Law is not violated if and when equilibrium is reached), it
            is not even clear how to calculate the production rate because there is no generally accepted definition of entropy away from equilibrium. Boltzmann's <i>S</i>=<i>k</i>ln<i>W</i> (relating
            entropy <i> S</i> to available microstates <i>W</i>) will not give it to us, nor will any other general law. While that is so, a quantitative non-equilibrium statistical mechanics remains
            hard to formulate. One possible way forward is to use as the appropriate variables of dynamical steady states the time-invariant probability measures developed in the 1970s by Yakov Sinai,
            David Ruelle and Rufus Bowen. </p>
        <p>But as yet, the theory of non-equilibrium remains largely a heuristic one. It is evident that lack of equilibrium does not imply lack of structure &mdash; many if not most of the richest
            patterns in nature (<figr rid="f2">Fig. 2 </figr>) are formed out of equilibrium. Microscopic models such as reaction&ndash;diffusion schemes do a fair job of capturing some of this
            behaviour, and &lsquo;toy&rsquo; equations such as the Swift&ndash;Hohenberg equation provide a general description of some of the symmetry-breaking processes that occur<bibr rid="b9"/>;
            but non-equilibrium systems seem particularly prone to the influences of boundary conditions, defects and noise, and remain resistant to too much generalization. </p>
        <p>All the same, some useful broad principles have appeared, among them the idea that certain non-equilibrium systems have a kind of imposed criticality said to be self-organized, in the sense
            that they will constantly return to a precarious critical state following some transient instability such as a landslide<bibr rid="b10"/>. The characteristic statistics of such systems,
            dubbed 1/<i>f</i> behaviour because of the inverse relationship between the size and frequency (<i>f</i>) of a fluctuation, provides a kind of fingerprint that alerts the observer to the
            likely appearance of scale-invariant structure and dynamics. Self-organized criticality seems to be a promising candidate for a general mechanism capable of forming the fractal structures
            so prominent in nature, from mountain ranges to the large-scale structure of the Universe. There is a clear kinship with the fractal &lsquo;optimal channel networks&rsquo; that have been
                posited<bibr rid="b11"/> as models of real river drainage networks. These are formed under the assumption that the evolution must minimize the rate of potential-energy dissipation in
            the water flow. The resulting topology of the drainage basin shows non-random 1/<i>f</i> statistics. To what extent this model captures the essential features of real river systems is
            still a matter of debate.</p>
        <p>And it remains to be seen whether self-organized criticality itself will prove to be generalizable to forest fires, epidemics, solar flares and the countless other physical systems in which
            such statistics have been reported. But the canonical example, the sand pile, points to another growth area in studies of the behaviour of matter &mdash; granular media. Capable of both
            solid-like and fluid-like behaviour, dominated by dissipative collisions and essentially independent of temperature, granular media represent a new class of problem for many-body
            theorists. There is still no general physical framework, comparable to the kinetic model of gases, able to predict the stupefying range of collective and self-organized behaviour exhibited
            by grains in motion: size segregation in vertical shaking and landslides, formation of ordered patterns<bibr rid="b12"/> (<figr rid="f2">Fig. 2</figr>), liquefaction, hysteretic angles of
            instability and so forth. Quite aside from the relevance of much of this for industrial powder processing, there is the matter of whether it might cast light on the geomorphology of grainy
            media distributed by wind and wave. </p>
        <p>Traffic flow is now understood to be a special case of granular flow, and exhibits dynamic states that bear striking analogy to the equilibrium states of matter. In low-density
            &lsquo;free&rsquo; flow, each vehicle moves more or less independently, like a gas. A traffic jam at high densities is resolutely solid-like, with equidistant particles trapped in near or
            total immobility. But jams rarely nucleate from free flow; instead, it seems that a dense, congested yet mobile state intervenes, the highway equivalent of a liquid state. Changes from one
            state to another seem to have the abrupt character of a first-order phase transition (like freezing or melting), relying on the presence of fluctuations to nucleate the change.</p>
        <p>Perhaps the hardest of non-equilibrium problems &mdash; turbulence &mdash; remains as obstinate as ever. The mathematician Sir Horace Lamb's famous quip &mdash; that he was more optimistic
            about receiving heavenly enlightenment on quantum electrodynamics than on turbulence &mdash; proved prophetic in terms of which would yield first, and turbulence still retains something of
            its reputation as a &lsquo;graveyard of theories&rsquo;. From a statistical physical perspective, the situation is nightmarish: every parcel of fluid acts non-trivially on the others,
            there is structure at all length scales, dissipation is very strong, and the solutions are wholly time-dependent. Ideas from critical phenomena might prove helpful for characterizing the
            scaling behaviour of turbulent flows. Yet questions remain, for example, about just how many distinct regimes of thermal turbulence (as a function of Rayleigh number, proportional to the
            temperature gradient) there are. Each regime is characterized by a specific scaling law relating Rayleigh number to heat transport; recent predictions of an &lsquo;ultrahard&rsquo; regime
            relevant to atmospheric dynamics have been met with conflicting experimental results<bibr rid="b13"/>. </p>
        <p>Even in equilibrium, a strong element of disorder in a system complicates the picture. The glass transition withholds some of its mysteries still, exemplifying a whole range of systems
            &mdash; among them spin glasses and folded proteins &mdash; in which the problem is that of finding a global energetic minimum in a rugged &lsquo;energy landscape&rsquo;. How this
            landscape is explored as a liquid is lowered towards its glass transition is in need of further clarification before a truly thermodynamic description of this transition can be developed.
            The conceptual tools needed for the job are also being usefully brought to bear on the vexed issue of protein folding. This compares with a glass in the sense that the system of particles
            (in this case interacting residues on the polypeptide chain) has a great many configurations that correspond to local free-energy minima, but only one &mdash; the native fold &mdash; that
            equates with the global minimum. The protein experiences &lsquo;frustration&rsquo; as it folds: an amino-acid residue cannot simultaneously optimize interactions with all its neighbours.
            Mapping this situation onto the case of frustrated magnetic spin glasses known in condensed-matter physics has helped to explain the wide range of protein folding speeds (a function of the
            degree of frustration) and has provided the useful concept of a folding &lsquo;funnel&rsquo;, the broad basin in the energy landscape that surrounds the deep well of the native fold<bibr
                rid="b14"/>.</p>
        <crosshd>Is physics rigorous?</crosshd>
        <p>It can be remarkably hard to prove rigorously the development of genuine long-ranged (crystal-like or ferromagnetic) order in an equilibrium phase transition &mdash; particularly if the
            degrees of freedom are continuous rather than discrete (for example, in Heisenberg rather than Ising models of magnetic states, where the spins can take any orientation). We
            &lsquo;know&rsquo; from numerical modelling that such systems do adopt long-range order in appropriate circumstances; but we cannot prove that they do so rigorously. Physicist Elliott
            Lieb's comment on this issue applies equally to many are&sect;as of physics: &ldquo;One might ask why one should bother to prove rigorously what is &lsquo;physically obvious&rsquo; and the
            answer is that &lsquo;Not everything that is obvious is true and the ability to prove something interesting about a model usually requires an additional degree of physical understanding
            that goes beyond intuition; in other words, we learn something new about physics&lsquo;.&rdquo;<bibr rid="b15"/></p>
        <p>Such rigour is, however, surely an impossible dream when one comes to apply the elegance of statistical physics to the orchestrated chaos we call life. Despite the proven value to cell
            biology of some concepts from the study of phase transitions &mdash; such as the entropic effect of fluctuations on interactions of lipid membranes &mdash; there remains much scepticism as
            to whether any biological phenomena can arise from the sort of collective, emergent behaviour of statistical, interacting ensembles rather than the closely controlled protein relays to
            which cell biologists are accustomed. Yet statistical physics must inevitably provide the baseline even in the cell: proteins may phase-separate and membranes may adopt equilibrium
            conformations unless actively opposed. The recent interest in thermal ratchets<bibr rid="b16"/> &mdash; Brownian systems that achieve directional motion by virtue of operating in an
            asymmetric underlying potential &mdash; attests to the contributions that microscopic physical models might make to cell biology. These models may or may not, in the end, have much to do
            with the way that motor proteins work; but they demonstrate that physics offers creative solutions to adaptive biological systems. The same can be said for the idea that stochastic
            resonance &mdash; the (counterintuitive) noise-induced amplification of a signal<bibr rid="b17"/> &mdash; is exploited in biological signal transduction. There now seems to be good
            evidence that this mechanism has some role in neural processing, and one might even be surprised if it did not turn out to be more general. In both of these cases, we see how noise &mdash;
            inevitable in any environment &mdash; can, with the right adaptation, serve a functional purpose.</p>
        <p>The considerable redundancy evident in the cell's machinery &mdash; so that cells continue happily with disabled genes that were supposedly central to their survival &mdash; suggests the
            need for some kind of nonlinear collective modelling of the interactions among its components. This is the kind of thing that physicists have been doing for years, and in increasingly
            complex systems. Cells provide perhaps the ultimate challenge, although the modelling will have to be dosed with a strong element of biological good sense.</p>
    </bdy>
    <bm>
        <objects>
            <fig id="f1" type="eps" entname="figf1">
                <!--402c73aa-->
                <figtl>The Ising model at the critical point.</figtl>
                <caption>
                    <p>Each site on this two-dimensional lattice can adopt one of two states &mdash; black or white, corresponding to &lsquo;up&lsquo; or &lsquo;down&rsquo; spins in a ferromagnet. At
                        the critical point, neither state predominates, and fluctuations occur on all length scales.</p>
                </caption>
                <credit>(Courtesy of Alistair Bruce, University of Edinburgh.)</credit>
            </fig>
            <fig id="f2" type="eps" entname="figf2">
                <!--402c73ab-->
                <figtl>Complex, ordered patterns form in vertically oscillated thin layers of grains.</figtl>
                <credit>(From <bibrinl rid="b12">ref. 12</bibrinl>.)</credit>
            </fig>
        </objects>
        <bibl>
            <bib id="b1">
                <reftxt><refau><snm>Widom</snm>, <fnm>B.</fnm></refau>
                    <jtl> Physica A</jtl>
                    <vid>263</vid>, <ppf>500</ppf> (<cd year="1999">1999</cd>). </reftxt>
            </bib>
            <bib id="b2">
                <reftxt><refau><snm>Mishima</snm>, <fnm>O.</fnm></refau> &amp; <refau><snm> Stanley</snm>, <fnm>H. E.</fnm></refau>
                    <jtl>Nature</jtl>
                    <vid>396</vid>, <ppf> 329</ppf> (<cd year="1998">1998</cd>).</reftxt>
            </bib>
            <bib id="b3">
                <reftxt><refau><snm>Bruce</snm>, <fnm>A.</fnm></refau> &amp; <refau><snm> Wallace</snm>, <fnm>D.</fnm></refau> in <btl>The New Physics</btl> (ed. Davies, P.) (Cambridge Univ. Press,
                        <cd year="1989">1989</cd>).</reftxt>
            </bib>
            <bib id="b4">
                <reftxt><refau><snm>London</snm>, <fnm>F.</fnm></refau>
                    <jtl> Nature</jtl>
                    <vid>141</vid>, <ppf>643</ppf> (<cd year="1938">1938</cd>).</reftxt>
            </bib>
            <bib id="b5">
                <reftxt><refau><snm>Bardeen</snm>, <fnm>J.</fnm></refau>, <refau><snm> Cooper</snm>, <fnm>L. N.</fnm></refau> &amp; <refau><snm>Schrieffer</snm>, <fnm> J. R.</fnm></refau>
                    <jtl>Phys. Rev.</jtl>
                    <vid>108</vid>, <ppf>1175</ppf> (<cd year="1957">1957</cd>).</reftxt>
            </bib>
            <bib id="b6">
                <reftxt><refau><snm>Anderson</snm>, <fnm>M. H.</fnm></refau>, <refau><snm> Ensher</snm>, <fnm>J. R.</fnm></refau>, <refau><snm>Matthews</snm>, <fnm> M. R.</fnm></refau>,
                            <refau><snm>Wieman</snm>, <fnm>C. E.</fnm></refau> &amp; <refau><snm> Cornell</snm>, <fnm>E. A.</fnm></refau>
                    <jtl>Science</jtl>
                    <vid>269</vid>, <ppf> 198</ppf> (<cd year="1995">1995</cd>).</reftxt>
            </bib>
            <bib id="b7">
                <reftxt><refau><snm>Bednorz</snm>, <fnm>J. G.</fnm></refau> &amp; <refau><snm> M&uuml;ller</snm>, <fnm>K. A.</fnm></refau>
                    <jtl>Z. Phys. B &ndash; Cond. Matt</jtl>
                    <vid>64</vid>, <ppf>189</ppf>&ndash;<ppl>93</ppl> (<cd year="1986"> 1986</cd>).</reftxt>
            </bib>
            <bib id="b8">
                <reftxt><refau><snm>Landauer</snm>, <fnm>R.</fnm></refau>
                    <jtl> Physical Rev. A</jtl>
                    <vid>12</vid>, <ppf>636</ppf> (<cd year="1975">1975 </cd>).</reftxt>
            </bib>
            <bib id="b9">
                <reftxt><refau><snm>Cross</snm>, <fnm>M. C.</fnm></refau> &amp; <refau><snm> Hohenberg</snm>, <fnm>P.</fnm></refau>
                    <jtl>Rev. Mod. Phys.</jtl>
                    <vid>65 </vid>, <ppf>851</ppf> (<cd year="1993">1993</cd>).</reftxt>
            </bib>
            <bib id="b10">
                <reftxt><refau><snm>Bak</snm>, <fnm>P.</fnm></refau>, <refau><snm> Tang</snm>, <fnm>C.</fnm></refau> &amp; <refau><snm>Weisenfeld</snm>, <fnm> K.</fnm></refau>
                    <jtl>Phys. Rev. Lett.</jtl>
                    <vid>59</vid>, <ppf>381</ppf> (<cd year="1987">1987</cd>).</reftxt>
            </bib>
            <bib id="b11">
                <reftxt><refau><snm>Rodriguez-Iturbe</snm>, <fnm>I.</fnm></refau> &amp; <refau><snm>Rinaldo</snm>, <fnm>A.</fnm></refau>
                    <btl>Fractal River Basins</btl> (Cambridge Univ. Press, <cd year="1997">1997</cd>).</reftxt>
            </bib>
            <bib id="b12">
                <reftxt><refau><snm>Melo</snm>, <fnm>F.</fnm></refau>, <refau><snm> Umbanhowar</snm>, <fnm>P. B.</fnm></refau> &amp; <refau><snm>Swinney</snm>, <fnm> H. L.</fnm></refau>
                    <jtl>Phys. Rev. Lett.</jtl>
                    <vid>75</vid>, <ppf>3838</ppf> (<cd year="1995">1995</cd>).</reftxt>
            </bib>
            <bib id="b13">
                <reftxt><refau><snm>Glazier</snm>, <fnm>J. A.</fnm></refau>, <refau><snm> Segawa</snm>, <fnm>T.</fnm></refau>, <refau><snm>Naert</snm>, <fnm>A.</fnm></refau> &amp;
                            <refau><snm>Sano</snm>, <fnm>M.</fnm></refau>
                    <jtl>Nature</jtl>
                    <vid> 398</vid>, <ppf>307</ppf> (<cd year="1999">1999</cd>).</reftxt>
            </bib>
            <bib id="b14">
                <reftxt><refau><snm>Wolynes</snm>, <fnm>P. G.</fnm></refau> &amp; <refau><snm>Eaton</snm>, <fnm>W. A.</fnm></refau>
                    <jtl>Physics World </jtl>
                    <vid>12</vid>(<iid>9</iid>), <ppf>39</ppf> (<cd year="1999">1999</cd>). </reftxt>
            </bib>
            <bib id="b15">
                <reftxt><refau><snm>Lieb</snm>, <fnm>E.</fnm></refau>
                    <jtl> Physica A</jtl>
                    <vid>263</vid>, <ppf>491</ppf> (<cd year="1999">1999</cd>). </reftxt>
            </bib>
            <bib id="b16">
                <reftxt><refau><snm>Astumian</snm>, <fnm>R. D.</fnm></refau>
                    <jtl> Science</jtl>
                    <vid>276</vid>, <ppf>917</ppf> (<cd year="1997">1997</cd>). </reftxt>
            </bib>
            <bib id="b17">
                <reftxt><refau><snm>Wiesenfeld</snm>, <fnm>K.</fnm></refau> &amp; <refau><snm>Moss</snm>, <fnm>F.</fnm></refau>
                    <jtl>Nature</jtl>
                    <vid> 373</vid>, <ppf>33</ppf> (<cd year="1995">1995</cd>).</reftxt>
            </bib>
        </bibl>
    </bm>
</article>
<?Pub *0000036269?>
